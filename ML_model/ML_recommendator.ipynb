{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091ae455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/MariloyHJimenez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import hvplot.pandas\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Dependencies\n",
    "import nltk\n",
    "nltk.download ('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b843b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98fbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/Philadelphia_businesses.csv\"\n",
    "df_restaurants = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af250e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_restaurats_Philly = df_restaurants.sort_values(by=['stars_business','review_count'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4140f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_restaurants (latitude, longitude):  \n",
    "    top_restaurants_df = df_restaurants.sort_values(by=[\"stars_business\",\"review_count\"], ascending=False)[:20]\n",
    "    \n",
    "    #Elbow method to determine the number of K in Kmeans Clustering\n",
    "    coords = df_restaurants[[\"latitude\", \"longitude\"]]\n",
    "\n",
    "    inertia = []\n",
    "    K = range(1,25)\n",
    "\n",
    "    # Calculate the inertia for the range of K values\n",
    "    for k in K:\n",
    "        kmeansModel = KMeans(n_clusters=k)\n",
    "        kmeansModel = kmeansModel.fit(coords)\n",
    "        inertia.append(kmeansModel.inertia_)\n",
    "    kmeans = KMeans(n_clusters= 5, init='k-means++')\n",
    "    kmeans.fit(coords)\n",
    "    y = kmeans.labels_   \n",
    "    \n",
    "    df_restaurants[\"cluster\"]= kmeans.predict(df_restaurants[['latitude', 'longitude']])\n",
    "    \n",
    "    top_restaurants_Philly = df_restaurants.sort_values(by=['stars_business','review_count'],ascending=False)\n",
    "     \n",
    "    df = top_restaurants_Philly \n",
    "    \n",
    "    # Predict the cluster for longitude and laltiude provided\n",
    "    cluster = kmeans.predict(np.array([latitude, longitude]).reshape(1, -1))[0]\n",
    "    #Get the best reataurant in this cluster\n",
    "    \n",
    "    return df[df[\"cluster\"]==cluster].iloc[0:50][['name', 'latitude', 'longitude','stars_business','categories','review_count','ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2055",
   "metadata": {},
   "source": [
    "# Importing Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72681d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data/Final_philadelphia_reviews.csv\"\n",
    "phillies_df = pd.read_csv(file_path)\n",
    "yelp_reviews_df = phillies_df[['review_id', 'user_id', 'business_id', 'text', \n",
    "                               'stars_business', 'review_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecbf66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with empty string the NaN reviews\n",
    "yelp_reviews_df.dropna(inplace=True)\n",
    "yelp_reviews_df[['text']] = yelp_reviews_df[['text']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e21806b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yelp_reviews_df.rename (columns={'review_id': 'Review_ID', 'user_id' :'User_Id', \n",
    "                        'business_id':'Business_Id', 'text':'Reviews', \n",
    "                'stars_business': 'Rating', 'review_count' :'Review_count'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebf0d2",
   "metadata": {},
   "source": [
    "# Begin the reviews cleaning, selecting only stars and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f2ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only stars and text\n",
    "reviews_df = yelp_reviews_df[['Business_Id', 'User_Id', 'Rating', 'Reviews']]\n",
    "reviews_df[\"Reviews\"] = yelp_reviews_df[\"Reviews\"].str.replace(\";\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f25c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "   # Check characters to see if they are in punctuation          \n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join t('stop_word(he characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return \" \".join([word for word in nopunc.split() if word.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89ca5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = []\n",
    "\n",
    "for word in stopwords.words('english'):\n",
    "    s = [char for char in word if char not in string.punctuation]\n",
    "    stop.append(''.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaaa48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['Reviews'] = reviews_df['Reviews'].apply(text_process)\n",
    "#Split train test for testing the model later\n",
    "vld_size=0.15\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(reviews_df['Reviews'], yelp_reviews_df['Business_Id'], test_size = vld_size) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c1851",
   "metadata": {},
   "source": [
    "# Create two tables of user, text and bussiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c265907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorizeReviews (rest_df):\n",
    "    newreviews_df = reviews_df[reviews_df['Business_Id'].isin(rest_df[\"Business_Id\"])]\n",
    "\n",
    "    userid_df = newreviews_df[['User_Id','Reviews']]\n",
    "    business_df = newreviews_df[['Business_Id', 'Reviews']]\n",
    "\n",
    "    userid_df = userid_df.groupby('User_Id').agg({'Reviews': ' '.join})\n",
    "    business_df = business_df.groupby('Business_Id').agg({'Reviews': ' '.join})\n",
    "\n",
    "    # User Tfdf Vectorizer  \n",
    "    userid_vectorizer = TfidfVectorizer(tokenizer = WordPunctTokenizer().tokenize, max_features=5000)\n",
    "    userid_vectors = userid_vectorizer.fit_transform(userid_df['Reviews'])\n",
    "    \n",
    "    #Business id vectorizer\n",
    "    businessid_vectorizer = TfidfVectorizer(tokenizer = WordPunctTokenizer().tokenize, max_features=5000)\n",
    "    businessid_vectors = businessid_vectorizer.fit_transform(business_df['Reviews'])\n",
    "    \n",
    "    #Matrix Factorization\n",
    "    userid_rating_matrix = pd.pivot_table(newreviews_df, values='Rating', index=['User_Id'], columns=['Business_Id'])\n",
    "    P = pd.DataFrame(userid_vectors.toarray(), index=userid_df.index, columns=userid_vectorizer.get_feature_names())\n",
    "    Q = pd.DataFrame(businessid_vectors.toarray(), index=business_df.index, columns=businessid_vectorizer.get_feature_names()) \n",
    "    P, Q = matrix_factorization(userid_rating_matrix, P, Q, steps=25, gamma=0.001,lamda=0.02)\n",
    "    return(P,Q, userid_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028b0ef",
   "metadata": {},
   "source": [
    "# Gradient Decent Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ffa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrix_factorization(R, P, Q, steps=25, gamma=0.001,lamda=0.02):\n",
    "    for step in range(steps):\n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    eij=R.loc[i,j]-np.dot(P.loc[i],Q.loc[j])\n",
    "                    P.loc[i]=P.loc[i]+gamma*(eij*Q.loc[j]-lamda*P.loc[i])\n",
    "                    Q.loc[j]=Q.loc[j]+gamma*(eij*P.loc[i]-lamda*Q.loc[j])\n",
    "        e=0\n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    e= e + pow(R.loc[i,j]-np.dot(P.loc[i],Q.loc[j]),2)+lamda*(pow(np.linalg.norm(P.loc[i]),2)+pow(np.linalg.norm(Q.loc[j]),2))\n",
    "        if e<0.001:\n",
    "            break\n",
    "        \n",
    "    return P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31cd8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store P, Q and vectorizer in pickle file\n",
    "import pickle\n",
    "#output = open('yelp_recommendation_model_8.pkl', 'wb')\n",
    "#pickle.dump(P,output)\n",
    "#pickle.dump(Q,output)\n",
    "#pickle.dump(userid_vectorizer,output)\n",
    "#output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e8c6e",
   "metadata": {},
   "source": [
    "# Run prediction according User's preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb6ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRecommendations (latitude, longitude, words):\n",
    "\n",
    "    recommendedlist = []\n",
    "    \n",
    "    #Call the first part of ML process.. finding 50 nearest restaurants \n",
    "    restaurants_df = recommend_restaurants(latitude,longitude)\n",
    "    restaurants_df.rename (columns={'ID':'Business_Id'}, inplace=True)\n",
    "    \n",
    "    #Process the user preferences\n",
    "    test_df= pd.DataFrame([words], columns=['Reviews'])\n",
    "    test_df['Reviews'] = test_df['Reviews'].apply(text_process)\n",
    "    \n",
    "    #Call the second part of the ML process...     \n",
    "    P, Q, userid_vectorizer = vectorizeReviews (restaurants_df) \n",
    "    test_vectors = userid_vectorizer.transform(test_df['Reviews'])\n",
    "    test_v_df = pd.DataFrame(test_vectors.toarray(), index=test_df.index, columns=userid_vectorizer.get_feature_names())\n",
    "\n",
    "    predictItemRating=pd.DataFrame(np.dot(test_v_df.loc[0],Q.T),index=Q.index,columns=['Rating'])\n",
    "    foundRestaurants=pd.DataFrame.sort_values(predictItemRating,['Rating'],ascending=[0])[:7]\n",
    "\n",
    "    for i in foundRestaurants.index:\n",
    "        name = restaurants_df[restaurants_df['Business_Id']==i]['name'].iloc[0]\n",
    "        categories =restaurants_df[restaurants_df['Business_Id']==i]['categories'].iloc[0]\n",
    "        latitude = restaurants_df[restaurants_df['Business_Id']==i]['latitude'].iloc[0]\n",
    "        longitude = restaurants_df[restaurants_df['Business_Id']==i]['longitude'].iloc[0]\n",
    "        rating = str(restaurants_df[restaurants_df['Business_Id']==i]['stars_business'].iloc[0])\n",
    "\n",
    "        case = {'Name': name, 'Categories': categories, 'Latitude': latitude, 'Longitude': longitude, 'Rating' : rating}\n",
    "        recommendedlist.append(case)\n",
    "        \n",
    "    topRecommend_df = pd.DataFrame (recommendedlist)\n",
    "    Data2geojson(topRecommend_df)        \n",
    "    return(True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c44078e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "from geojson import Feature, FeatureCollection, Point\n",
    "\n",
    "\n",
    "def Data2geojson(df):\n",
    "    features = []\n",
    "    insert_features = lambda X: features.append(\n",
    "                    geojson.Feature(geometry=geojson.Point((X[\"Longitude\"],\n",
    "                                                    X[\"Latitude\"])),\n",
    "                    properties=dict(name = X[\"Name\"],\n",
    "                                    description = X[\"Categories\"],\n",
    "                                    rating = X['Rating']))\n",
    "                    )\n",
    "    df.apply(insert_features, axis=1)\n",
    "    with open('Templates/top7recommendations.geojson', 'w', encoding='utf8') as fp:\n",
    "        geojson.dump(geojson.FeatureCollection(features), fp, sort_keys=True, ensure_ascii=False,indent=4)  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7d478dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#findRecommendations(39.951732, -75.142140, \"spaguetti music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a6a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
